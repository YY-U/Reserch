# ディープ ラーニング、自然言語処理、空間分析を使用して、災害関連のツイートとその意味的、空間的、時間的コンテキストを特定する: ハリケーン イルマのケース スタディ(Identifying disaster-related tweets and their semantic, spatial and temporal context using deep learning, natural language processing and spatial analysis: a case study of Hurricane Irma)
# 概要
我々は、ツイートを分析するための分析フレームワークを導入し、（1）被災した個人、破損したインフラ、中断したサービスなど、災害に関する細かい詳細を特定し分類する、（2）影響地域と時間帯、および空間と時間にわたる災害関連情報の各カテゴリの相対的な卓越性を区別する、ことを目的とする。我々はまず、人間がラベル付けしたトレーニングデータセットを生成し、災害関連性の二値分類のために一連のディープラーニングと機械学習の手法を実験することによって、災害関連ツイートを識別します。我々は分類タスクにLSTM（Long Short-Term Memory）ネットワークを採用する。LSTMネットワークは長期の意味的な単語と特徴の依存関係を用いてテキスト構造全体を考慮することで他の手法より優れた性能を発揮するからである。第二に、LDA（Latent Dirichlet Allocation）を用いた教師無しマルチラベル分類を採用し、被災者やサービス障害など、ツイートの潜在的なカテゴリを特定する。第三に、空間適応型カーネルスムージングと密度ベースの空間クラスタリングを採用し、各情報カテゴリの相対的な顕著性と影響領域をそれぞれ特定する。ハリケーン・イルマをケーススタディとして、災害前、災害中、災害後の5億件以上のキーワードベースおよび地理的位置情報を持つツイートのコレクションを分析しました。その結果、災害の時間的な進展を通じて、被災した個人やインフラの被害が密集している潜在的な地域が浮き彫りになりました。

# 1.はじめに
ビッグデータの時空間分析の最近の進歩と危機的状況におけるソーシャルメディアデータの広範な使用により、環境モニタリング (Demir et al. 2015) と災害管理 (Li et al. 2018) のためのサイト固有の情報の抽出が可能になります。 このような情報は、準備、対応、復旧など、災害管理のあらゆる段階で非常に貴重です (Krajewski et al. 2017)。 緊急事態と被害の場所は、目撃情報を生成および拡散し、ソーシャル メディア プラットフォームを使用して状況認識を可能にするソーシャル センサーまたは個人を通じてキャプチャできます。 ソーシャル センシングと災害情報のマルチソース分析は、多くの研究者によって災害の影響を評価するためにうまく採用されています (Cervone et al. 2016; De Albuquerque et al. 2015; Feng and Sester 2018; Huang, Cervone, and Zhang 2017; Li et al. 2018; Restrepo-Estrada et al. 2018)。 ソーシャル メディア データのノイズ、および共有情報の場所と文脈の不確実性により、分析が遡及的に行われる場合、市民センサーによってリアルタイムまたはイベントの余波で生成される有用で実用的な情報を抽出することは困難です。 復旧作業を調整します。  

深層学習と機械学習の手法が大幅に進歩したにもかかわらず、以前の研究者 (Burel et al. 2017 ; Nguyen et al. 2016 ; Olteanu et al. 2014 ) は、影響を受けた個人などの情報の細かい詳細を分類するパフォーマンスが低いことを報告しています。ソーシャルメディアデータからの寄付とサポート、そして同情と祈り。ソーシャル メディア メッセージを分類する際の課題は、多くの場合、データのノイズ、オンライン ワーカーとボランティアによって行われた競合する注釈、およびツイートが複数のカテゴリに属する​​可能性があるマルチラベルの問題に起因しています (Nguyen et al. 2016）。さらに、ソーシャル メディアを通じて送信されたメッセージの所在とタイミングを考慮して、災害関連情報の詳細な分類を改善する必要性が非常に高くなります。  

この記事では、2 段階の分類アプローチと空間分析を統合する分析フレームワークを紹介します。(1) ツイートから、影響を受けた個人、インフラストラクチャの損傷、サービスの中断などの災害に関する詳細を特定して分類し、(2) 区別します。影響地域と期間、および空間と時間にわたる災害関連情報の各カテゴリの相対的な卓越性。私たちの分析フレームワークは、次のステップで構成されています。ハリケーン イルマをケース スタディとして使用し、ハリケーン イルマの影響前、最中、後に生成された 20,000 (5%) のキーワードベースの地理位置情報コーパスを手動でラベル付けすることにより、コンテキスト固有のトレーニング データセットを最初に開発しました。トレーニング データセットを生成した後、ロジスティック回帰、線形サポート ベクター マシン (SVM) やリッジなどの線形分類器、畳み込みニューラル ネットワーク (CNN) や長短期記憶 (Long Short Term Memory) などのディープ ラーニングおよび機械学習手法を含む一連の分類手法を使用して分類実験を行います ( LSTM) ネットワーク。LSTM ネットワークは、長期的なセマンティック ワードと機能の依存関係を使用して単語の順序とテキスト構造全体を考慮することにより、他の方法よりも優れているため、分類タスクに LSTM ネットワークを使用します。分類方法に関する私たちのトレーニング データと実験は、ハリケーンに関するツイートをリアルタイムで遡及的に分類することを目的とした将来の研究に貴重な情報を提供します。あらかじめ決められたカテゴリでツイートの種類を分類する教師あり手法とは異なり、災害関連のつぶやきをバイナリ分類した後、Latent Dirichlet Allocation (LDA) を使用して、ターゲット ユーザーが多様な情報の詳細なカテゴリを抽出します。たとえば、影響を受けた個人とインフラストラクチャの損傷カテゴリを特定します。これは、緊急対応者、救助隊、公益事業会社を対象としています。寄付とサポートのカテゴリ。回復と救援活動を計画するための政府組織と非営利団体を対象としています。動物の管理とシェルターを対象とする、影響を受ける個人とペットのカテゴリ。アドバイス、警告、アラートのカテゴリは、状況認識の構築と強化のために地方自治体と FEMA を対象としています。  

情報の種類で災害関連のツイートを識別した後、空間適応カーネル平滑化法を使用して、情報の種類ごとに平滑化されたレートを計算します。最終的に、平準化されたレートにより、インフラストラクチャの損傷、影響を受けた個人、サービスの中断などの重大な影響がある領域、およびアドバイスと注意、寄付と支援、同情と支援などの他の種類の情報が提供された領域と期間を特定できます。祈りがより際立ちます。アダプティブ カーネル スムージングを使用して、地理空間全体でツイートの各カテゴリの相対的な卓越性をキャプチャすることに加えて、ノイズを使用した密度ベースの空間クラスタリング (DBSCAN) を使用して、各カテゴリのツイートの密度が高い領域を特定します。各カテゴリの確率の平滑化された曲面とは異なり、DBSCAN を使用すると、あるカテゴリに属する​​ツイートの絶対密度が定義されたしきい値よりも大きい領域を特定できます。最後に、ツイートの空間的および時間的パターンを降雨と洪水のデータと重ね合わせて、緊急対応と復旧作業の潜在的な地域を特定し、ハリケーン中のソーシャル メディアの使用における潜在的な地理的バイアスを特定します。  

# 2. 関連作品
危機的状況におけるマイクロブログの行動を分析した以前の研究では、危機的状況の種類と段階によって共有される情報が大きく異なることが一般的に報告されています (Kanhabua and Nejdl 2013 ; Munro and Manning 2012 ; Olteanu et al. 2014 )。一方、Olteanu、Vieweg、Castillo ( 2015 ) は、さまざまな自然災害や人為的災害を調査した結果、さまざまな危機的状況で人々がどのように情報を共有するかについて、一貫性と共通性を発見しました。最も一般的な調査結果の 1 つは、危機的状況では公開情報を求めることが増加することです (Hagen et al. 2017 ; Nelson, Spence, and Lachlan 2009)、人々はソーシャル メディアをリソースとして利用して、場所や状況に関する情報を共有することで、助けを求めたり、取り組みを調整したりします (Stefanidis et al. 2013 )。ソーシャル メディアは、より多くの人に情報を広め、緊急警報を送受信し、情報拡散を制御し、緊急対応者と協力し、状況認識を生み出すことにより、危機コミュニケーションにおいて重要な役割を果たします (Lachlan et al. 2016 )。公共の情報探索におけるソーシャル メディアの利用は、ジカ ウイルスの蔓延 (Hagen et al. 2017 )、ミネソタ州の橋の崩壊 (Nelson, Spence, and Lachlan 2009 )、メキシコの麻薬戦争 (Monroy-Hernández et al.2013 )、アラブの春 (Kumar et al. 2013 )、ハイチ地震 (Caragea et al. 2011 )、多数の洪水イベント (Kongthon et al. 2012 ; Kwon and Kang 2016 ; Maantay, Maroko, and Culp 2010 ; Restrepo- Estrada et al. 2018 )。  
危機的状況における自動イベント検出は大幅に進歩しましたが、影響を受けた個人や損傷したインフラストラクチャなど、イベントに関連する詳細な情報を抽出することは依然として困難です (Burel et al. 2017 )。イベント検出を改善するために、多くの戦略が導入されました。たとえば、Zhang、Szabo、Sheng ( 2016 ) は、語彙分析とユーザー プロファイリングを組み合わせて、情報の内容と種類だけでなく、情報のソースも分析しました。Pekar等。( 2016 ) メタデータから派生したセマンティックおよびスタイルの特徴がリコールの改善に役立つ一方で、語彙の特徴がより良い精度を達成するのに役立つことを発見しました。表1(1) ソーシャルセンサーからの災害関連情報を分類するためのオントロジー、(2) 災害関連のつぶやきと情報カテゴリを区別するための分類方法、(3) 場所固有の情報をソーシャルメディアと統合する研究。災害管理の指針となるデータ。  
![picture 2](../../../images/3bc66ad24bfdfbccbc943ea43e3cb419ba1090c0d2c701cd0615476bdafd14b5.png)  

# 3. ケーススタディ: ハリケーン イルマ
2017 年 9 月、ハリケーン イルマ (カテゴリー 5 の嵐) はカリブ海諸島とフロリダを破壊的な風、大雨、洪水で壊滅させました。ハリケーン地域は、大規模な停電、人命の損失、空港、病院、学校などのインフラストラクチャの損傷に見舞われました。多くの地域が居住可能になり、インフラを再構築するために数十億ドルの損害が発生する可能性があります。フロリダの沿岸地域に住む何百万人もの人々に影響を与える大規模な避難命令が出されました。イベント期間中は、情報を広め、災害対応と復旧作業を調整するために、ソーシャル メディアが広く使用されました。機関は Twitter を使用して、ハリケーンの軌跡と避難情報に関する最新情報を投稿しました。ソーシャルメディアは救援活動の効果的な要素となり、目撃情報を抽出し、状況認識の発達に役立ちます。地震、山火事、地滑りなどの他の災害と比較して、ハリケーンの予測可能性により、イベントの前と最中にソーシャルセンシングデータを収集できます。これは、準備と緊急対応の取り組みを計画するために非常に貴重です.  

# 4. 方法論
この記事では、ハリケーンの発生前、発生中、発生後に生成された災害関連のツイートを特定、分類、分析するための分析フレームワークを紹介します。私たちの全体的な目的は、準備、対応、回復の各段階を含むハリケーンの進行に関連する可能性のある有用な情報を収集することです。図1分析フレームワークを示しています。最初のフェーズには、データ収集、トレーニングおよびテスト データ収集のためのサンプリング設計と手順、およびさまざまな分類方法を評価するためのトレーニング セットとテスト セットの分類実験が含まれます。第 2 段階では、LSTM を使用した災害関連ツイートのバイナリ分類と、詳細情報のマルチラベル分類が含まれます。トレーニングデータをトレーニングセットとテストセットに分割することにより、最初に、災害関連情報のバイナリ分類に関する分類方法ロジスティック回帰、線形 SVM、リッジ、CNN、および LSTM のパフォーマンスに関する実験を行います。評価結果と、テキスト データの順序に対する LSTM の概念的な適合性に基づいて、LSTM を選択して残りのデータセットを関連ツイートと非関連ツイートに分類します。次、教師なしトピック モデリング アプローチを使用して、ツイートから被災者、アドバイスと警告、祈りとサポートなどの災害関連のツイートに関する情報の詳細なカテゴリを抽出します。次に、空間適応カーネル スムージングと密度ベースの空間クラスタリングを使用して、各情報カテゴリの相対的な卓越性と影響領域をそれぞれ特定します。最後に、分類されたツイートの空間的および時間的パターンを降雨と洪水のデータと重ね合わせて、緊急対応と復旧の取り組みが必要な地域を特定し、ハリケーン中のソーシャル メディアの使用における地理的バイアスを特定します。  

図 1.ツイートから災害関連情報と影響範囲を特定するための分析フレームワーク。  
![picture 1](../../../images/8b28a362479fb9a918cf5d52fc7a03130257a6140fb091ba323e6f2ea036bba9.png)  

## 4.1. データ収集、トレーニング サンプリングの設計とモデリング
この調査では、Twitter のストリーミング API によって収集された 3 つの Twitter データのコレクションを使用しました。最初のデータセットは、災害イベントに関連する任意のツイートを取得するためのもので、ハリケーン関連の 11 個のキーワード (「洪水」、「イルマ」、「ハリケーンイルマ」、「イルマハリケーン」、「イルマ 2017」、「ハリケーン」、「被害」、「嵐」、「雨」、「災害」、'emergency' ) を使用して収集されました。災害中に統計的に言及されたキーワードを特定するために統計的手法は使用しませんでしたが (Huang et al. 2018)、私たちは、災害の間最も頻繁に使用されたハッシュタグを使用して、キーワードを継続的に更新しました。2 番目のデータセットは、イルマの影響範囲をカバーする空間バウンディング ボックスを使用して収集し、災害の前、最中、およびその後の地理位置を特定したツイートを取得しました。最初と 2 番目のデータセットには、2017 年 9 月 1 日から 2017 年 10 月 15 日までの期間のツイートが含まれています。 最後に、2017 年 5 月から 2018 年 1 月の日付の間に米国本土からランダムに選択された、地理的に特定されたツイートの 3 つ目のデータセットを使用しました。3 番目のデータセットを使用して、トレーニング データ コレクションにノイズを組み込みました。。3 番目のデータセットからランダムなツイートを選び、分類モデルのノイズを導入して、学習を強化し、調査期間のツイートによって引き起こされるオーバーフィッティングを防止しました。3 つのデータセットを組み合わせたデータベースには、処理とフィルタリングの前に 756,913,748 件のツイートが含まれていました。キーワードベースのコレクションは 64,266,068 のツイートで構成されており、これらのツイートの 99% には少なくとも州レベルの地理位置情報が含まれています。これらのツイートの約 64% がリツイートでした。  

トレーニング サンプルの 3 番目のデータセットからランダムに選択されたジオロケーションのツイートをフィルタリングせずに含めました。一方、分類前に、1番目と2番目のデータセットに次の手順を適用しました。(1) 件のリツイートを削除しました。(2) ツイート ID による重複ツイート。(3) 2 番目のデータセットからの、最初のデータセットからのキーワードのリストから派生した、事前に決定された一連のキーワードを含まない、地理的に配置されたツイート (表 2); (4) ツイートソースのメタデータを使用した、天気アプリやボットなどの非個人ユーザーアカウントからのツイート。表 3ツイートの上位のソースと、それらをフィルター処理したかどうかを一覧表示します。(5) 2017 年 8 月 29 日から 2017 年 10 月 16 日までの期間外のツイート。(6) 地理的位置に関する情報を含まないツイート、またはハリケーン イルマの進路の影響範囲外にあるツイート。フィルタリング後、データは 1 か月半の期間にわたる 557,541 ツイートに削減されました。  

![picture 4](../../../images/0681afb094b6ae7e25ac014031c9e5ce2c800355a634bb18bdc7b14fb09be510.png)  

![picture 5](../../../images/c85ef8c7c5bb1644ef19594ace54283448fb43df70b48b6821c7c4a20bd09f9c.png)  


私たちは、ツイートがハリケーン、洪水、または極端な気象イベントに関連しているかどうかという、ツイートのバイナリ分類用のトレーニング データを収集するための Web ベースのインターフェイスを設計しました (図 2(b))。ツイートにラベルを付けるために、著者、学部生、大学院生で構成されるチームを編成しました。関連するツイートと関連しないツイートの両方の例を使用して、タスクに基づいてチームをトレーニングしました。私たちは、情報を提供するかどうか、目撃情報、ニュース記事、警告、政府への批判、極端な気象現象、洪水、ハリケーンに関する政治的議論に関するツイートを検討しました。Web インターフェイスには、ツイートが元の形式で表示され、質問に答える「はい」と「いいえ」のボタンが含まれています。ツイートに関連性​​があるかどうかわからない場合にユーザーがツイートをスキップできるように、「わからない」ボタンを追加しました。Web インターフェースは、例を使用してツイートにラベルを付ける方法の説明から始まります (図 2(a))。ハリケーン イルマに固有のものとは対照的に、質問を一般的なものにしました。これは、イルマの期間がハービー、マリア、ホセなどの他のハリケーンと重なっており、データセット内のツイートの一部が他のハリケーンに関連していたためです。これにより、これらの複数のイベントの分類タスクに使用できる可能性のある汎用トレーニング データセットを生成することができました。ヒューマン コーダーのチームと Web ベースのインターフェイスを使用して、約 20,000 件のラベル付きツイートを収集しました。  

図 2. (a) ラベル付けタスクの手順 (b) トレーニング データ収集インターフェイス。「いいえ」および「はい」ボタンを使用して、ユーザーが提示されたツイートに「関連」または「関連なし」のラベルを付けることができます。または、「わからない」ボタンを使用してツイートをスキップします。  
![picture 6](../../../images/7b63d1c392a8cda73b36b65c953cd0458f30d88c09332d0978796cfaff3bcb5f.png)  

## 4.2. ツイートの二値分類
トレーニング データを使用して、ロジスティック回帰、サポート ベクター マシン (SVM)、畳み込みニューラル ネットワーク (CNN)、および長短期記憶 (LSTM) ネットワークを使用して分類実験を実行しました。 以下のサブセクションでは、これらの各モデルとパラメーターについて説明します。  

### 4.2.1. ベースライン分類子
比較のために、2 つの異なるタイプの機械学習分類器を選択しました。(1) ベースライン分類器を取得するためのガウス カーネルを使用した SVM (2) ガウス SVM の前にパイプライン化された主成分分析 (PCA) 要約ステップを使用したモデル。 2 番目のモデルを使用して、分類タスクに対する PCA の効果を評価しました。 また、ロジスティック回帰、線形 SVM、リッジなど、いくつかの線形分類器の結果も評価しました。 これらの線形分類器は、問題の線形性が固定されているため、同様の結果が得られると予想されます。 ガウス SVM は類似度関数として放射基底関数 (RBF) を使用しますが、線形 SVM は線形類似度関数を使用します。 したがって、類似関数の違いにより、それらは異なる点に収束します。 分類の精度を向上させるために、これらのモデルの代替パラメーターと最適化設定を評価し、結果セクションで 5 つのモデルすべての実験結果を報告します。  

### 4.2.2. 畳み込みニューラル ネットワーク (CNN)人工ニューラル
ネットワーク (ANN) は、テキスト分類タスクに広く使用されている深層学習手法です。 ANN は、処理する学習教材 (トレーニング セット) から関連する特性を段階的に学習および進化させることにより、現象の特徴 (災害に関連する単語、単語の組み合わせなど) を学習できるようにします。 ANN は、現象に関する予備知識を必要としません。 ANN のカテゴリとして、畳み込みニューラル ネットワーク (CNN) は、テキスト分類タスクで一般的に使用されてきました。 通常のニューラル ネットワーク レイヤー内のノードの完全な接続を排除することで、CNN はトレーニング プロセスを高速化しながら、非線形モデルを作成する能力を維持します。 CNN は画像としての入力の概念で開発されたので、CNN は一般に画像の幅と高さ、および画像のカラー チャネルをそれぞれ表す幅、高さ、深さを持つ 3D ニューロン構造を利用します。 CNN は主に画像を含むタスクで使用されますが、テキスト分類で効率的かつ効果的なモデルを生成することもできます (Burel、Saif、および Alani2017)。  

分類タスクはバイナリであるため、シグモイド (式 (1)) 関数を使用しました。 出力レイヤーの最終的なアクティベーションとして、出力値を [0, 1] セットにマップします。 シグモイド関数の出力は、0.5 のしきい値を使用して 0 または 1 のクラスに変換できます。 CNN 構造の損失関数としてバイナリ クロス エントロピー (式 (2)) を使用しました (図 1)。 バイナリ クロス エントロピー関数は、モデルによって行われた予測と実際の値との距離を測定します。 次に、このコストを最小限に抑えるために、ニューラルネットワークが更新されます。  

シグモイド関数、ニューラル ネットワーク アーキテクチャの活性化関数  
![picture 7](../../../images/1d3858fed9a33f34dc38d1e7c884158e3fc0ac5ed6f808936dc9279a8b6cf779.png)  

損失関数として使用されるバイナリクロスエントロピー関数  
![picture 8](../../../images/ec15554d77f058721f6e2c62bb9f6e13547800009fed19dbee80251b752d408a.png)  

図 3 は、畳み込み層とそれに続く 2 つの完全に接続された層で構成される、提案された CNN モデルのアーキテクチャを示しています。 入力は、畳み込み部分に供給する前に埋め込まれます。 ドロップアウトと追加のプーリング レイヤーが一部のレイヤーの出力に適用され、フィッティングの防止と制御が行われます。  
![picture 9](../../../images/0af6e48a953eaf7599196dbbf207840345b488855b09999cdf799998c6d5c996.png)  

### 4.2.3. 長短期記憶 (LSTM) ネットワーク
CNN は堅牢な分類器を作成する可能性がありますが (Burel et al.2017; Nguyen et al.2016)、トレーニング プロセス全体で機能を記憶することには限界があります。 リカレント ニューラル ネットワーク (RNN) には、各ステップでトレーニングされるメモリ ベクトルのペアが組み込まれています。これらは、トレーニングの次のノードまたはステップに移動されます。 たとえば、単語シーケンスでは、前の単語と意図した出力との相関関係が、後の単語の意味および可能な推論に影響を与える可能性があります。 この前の単語と出力との相関関係は、文の連続的な性質を捉えるために、次のノードに引き継がれる必要があります。 「バニラ」RNN では、学習されて特徴ベクトル (隠れた状態) に保持されている情報が不規則に変化します。 消失勾配の問題により、ニューラル ネットワークの重みは、学習プロセスを妨げる損失の勾配のごくわずかな割合を受け取ります。 その結果、重みを学習するプロセスが遅くなるか、停止することさえあります。 したがって、単純で控えめな RNN は、長い間学習した機能を記憶することができません。 これは主に、テキスト分類タスクの全体的な精度に影響します。  

長短期記憶ニューラル ネットワーク (Hochreiter と Schmidhuber 1997) は、短期記憶の寿命を延ばして、より多くの機能をディープ ニューラル ネットワーク モデルに継承します。 LSTM とそのバリエーションは、画像分類 (Byeon et al.2015)、テキスト分類 (Liu、Qiu、Huang2016)、時系列分析 (Xingjian et al.2015) など、より長いメモリを必要とする分類タスクで広く使用されています。 図 4 と式 (4) ～ (9) は、LSTM ノードの概要と LSTM ノードの数学的背景を示しています。 LSTM ノードはテンソル xt と ht−1 に適用されます。ここで、xt は入力を表し、ht−1 は層内の前の LSTM ノードの隠れ状態を表します。 シグモイド関数は式(1)のσ(.)で表され、tanh(x)は双曲線正接関数を表します(式(3))。  
![picture 10](../../../images/2bdc5d2fed4028950a9eedb5c965d2058e649f43ed1e34935d067e86215c640b.png)  

重み行列 W および U は、入力および隠れ状態ベクトルを変換し、it、ft、ot、および ̃ct 値、すなわち入力ゲート (式 (4))、忘却ゲート (式 (5))、出力ゲート (式 (6)) を形成します。 およびセル更新ゲート (式 (7)) です。 これらのゲートのおかげで、LSTM は、以前のノードで学習されたが現在は廃止されている機能を削除するための忘却メカニズムを提供します。 ° 演算子は要素ごとの積を表し、LSTM ノードの出力はこれらのゲートを使用して計算されます。 情報をセル状態 (式 (8)) に保持しながら、LSTM ノードは、RNN の隠れ層に似た隠れ状態 (式 (9)) ですぐに使用される情報を記憶します。 最後に、隠れ状態とセル状態が次の LSTM ノードに伝達され、隠れ状態がニューラル ネットワーク アーキテクチャの次の層に伝達されます (図 5)。  
![picture 11](../../../images/79b8dfa6c56cee7d6f3bc7a3dde3cb5100d68dd8ef4415a329d0c40aea3819b0.png)  

![picture 12](../../../images/d98e215c721ea0040fb08076f9d1dcd70a3bb15af55a59591c25e76ce8977381.png)  

![picture 13](../../../images/5b5fe68df87267cd72fd4f7ed82959011cfbd0be3981ee7f0e8b2ecd10d4f85f.png)  

![picture 14](../../../images/a8778f3f9212772c03ce565cbfa03933474519e9e640b7e95146bec279543547.png)  

ここで提案するディープ ニューラル ネットワークは、埋め込み層やドロップアウト層などの他の層と共に LSTM ネットワークに依存します (図 6)。 提案された CNN モデルと同様に、LSTM でシグモイド (式 (1)) およびバイナリ クロス エントロピー (式 (2)) 関数を使用しました。 また、バイナリ クロス エントロピー関数よりも優れたパフォーマンスを生成したカテゴリカル クロス エントロピー関数も評価しました。したがって、カテゴリカル クロス エントロピー関数の結果は報告しません。  

![picture 15](../../../images/b51c7bff22e184308c2b6c09f4e83c3a3a0e8774440bb357899c0bf2ee62dc82.png)  

### 4.2.4. データセットのベクトル化
ツイートをベクトル化して、ツイート テキスト、日付とタイム スタンプ、およびトレーニング データセットの収集中に人間の分類器によって割り当てられたバイナリ ラベルを含む配列を作成しました。 ツイート エントリの例を以下に示します。  

Dx=[ツイート本文、日時、ラベル]、
Dx=[" 裏庭で大洪水 https://t.co/UJn3s", "2017 年 9 月 12 日 22.13 ET", 1].  

データセット内の情報をあらゆる種類の確率的分類器にフィードするには、データセットをベクトルで表す必要があります。 データをベクトルに変換する前に、ノイズの多いツイートを除外する前処理を実行しました。 まず、あらゆる種類の句読点と URL を消去し、すべての文字を小文字に変換しました。 次に、テキストを単語のシーケンスに分割します。このシーケンスはベクトルとして再構築されます。 前処理ステップの最後に、トークン化の次のステップのために、各ツイートのトリプル (ツイートの内容、日付と時刻のスタンプ、およびラベル) を導き出しました。  

Dx = [["メジャー","洪水","で","私の","裏庭"], "2017 年 9 月 12 日 22.13 ET", 1].  

順序付けステップの後、トークン化中心のアプローチを使用して各ツイートをベクトルに変換しました。これは、データセット全体での各単語の出現回数に基づいています。 データセット内に単語が出現するほど、ネットワークの初期化における機能としての効果が少なくなります。データセット内の単語を出現順に並べ替え、各単語をインデックスで置き換えるために 1 から始まるインデックスを割り当てました。 たとえば、単語「洪水」はデータセット全体で最も頻度が高いため、そのインデックス (置換) は 1 です。以下は、単語が整数インデックスに置き換えられた変換されたトリプルです。  

Dx=[[515, 252, 34, 17, 4200], "2017 年 9 月 12 日 22.13 ET", 1].  

各ツイートの長さは異なるため、ツイートをパディングして同じ長さのベクトルを構築し、それらをニューラル ネットワークにフィードすることが重要です。 ベクトル化プロセスのさまざまなサイズを経験的にテストしました: 25、30、35、40、45、50、55、および 60。50 の長さのベクトル化されたデータセットの分類テスト精度は、提案された LSTM アーキテクチャのすべてのベクトル長オプションの中で最高の結果を示しました。  

1 つの列はツイートの投稿日用に使用され、残りの列はツイート トークン用に使用されました。 したがって、ツイートからセマンティクスを導出するためのベクトル サイズの最適な数 (49 ワード トークン + 1 日付列) として 50 を選択しました。 この仮定に従って、すべてのベクトルをパディングして、ツイートごとに 49 語の長さのゼロのベクトルを生成しました。  

Dx=[[0,...0, 515, 252, 34, 17, 4200], "2017 年 9 月 12 日 22.13 ET", 1]  

ツイートの投稿日と洪水や異常気象との関連性を明らかにするために、ツイートの投稿日をツイート ベクトルに組み込みました。 日時のタグ付けは、分、時間、日、週など、さまざまな時間の粒度で実行できます。 洪水は突然発生する可能性がありますが、その影響、つまり洪水による浸水は、多くの場合、数日、数週間、場合によってはそれ以上の期間続きます。 私たちの目的は、ハリケーン イルマの計算中および計算後を含む長期間にわたる災害の進行を捉えることであったため、洪水イベントの発生と期間、および計算後の影響を考慮して、時間分解能として日を選択しました。 ハリケーンの。 その結果、2017 年 8 月 29 日から 2017 年 10 月 17 日までの日付を 1 から 50 までの整数スケールにマッピングし、整数を特徴ベクトルに追加しました。 最後に、データセット内の各ツイートに対して長さ 50 のベクトルを導出しました。ツイートの例の最終的なベクトルを以下に示します。  

Dx=[[0,...0,515,252,34,17,4200],15,1].  

## 4.3. 災害関連情報の主題分類
洪水、ハリケーン、異常気象に関連するツイートを分類した後、教師なしトピック モデリング アプローチである潜在的ディリクレ配分法 (LDA) を使用して、影響を受けた個人、寄付とサポート、注意とアドバイスなどの詳細な情報をツイートのコンテンツから抽出しました。 LDA は、単語の多項分布として定義された潜在トピックのコレクションを発見できる文書のベイジアン確率モデルです (Blei、Ng、および Jordan2003)。 LDA は、トピックの混合を各ドキュメントに割り当てます。  
![picture 16](../../../images/1ee6e274ed4c969dbb69687b6667e3bc36f4d39c0810af40037c06f4c887af7d.png)  

各トピック Z,P(Z|W,D) について、単語 W がトピック Z に由来する確率は、Z 内の W の正規化された頻度に、ドキュメント D 内の既に Z に属している他の単語の数を掛けることによって計算されます。 β や βw などは、単語 W が Z に関連付けられていない場合でも、単語 W がトピック Z に属する確率を組み込むために使用されます (Blei、Ng、および Jordan 2003)。

LDA は、ドキュメントのコレクションを単語ごとに繰り返し処理し、各単語をトピックに再署名します。 各反復の後、モデルは特定の単語やドキュメントを含むトピックとしてより一貫性があり、コレクションが許す限り一貫性のある平衡に達します (Goldstone and Underwood 2012)。 単語は、頻度が高いほどトピックでより一般的になり、ドキュメントでより頻繁に出現するトピックはドキュメントでより一般的になります。 各ツイートをドキュメントとして使用して、トピック モデルをトレーニングしました。 最初にツイートをトークン化して小文字に変換し、Mallet Toolkit (McCallum2002) を使用してモデルをトレーニングする前に、28 の言語からストップ ワード (「the」、「of」、「am」などの一般的に使用される単語) を使用しました。 . ステミングは結果にノイズをもたらし、トピック モデルの解釈を改善しないため、ステミングを使用しませんでした (Schofield and Mimno 2016)。

## 4.4. 空間適応カーネル スムージング
各ツイートが一連のトピックに分類されると、単位面積あたりの平均トピック確率を計算できます。 たとえば、フロリダ州サラソタ郡の災害関連の 1000 件のツイートから、被災者などのトピックの平均確率を計算できます。被災者カテゴリに属するツイートの確率の合計を、郡内で生成された災害関連のツイートの総数で割るだけです。ただし、このようなアプローチは、災害の影響と任意に割り当てられた行政境界との間の不一致により、変更可能な領域単位の問題 (MAUP) に悩まされる可能性があります。 さらに、異なる地理的領域に対して計算されたレートは、空間単位全体で人口サイズ (この場合はツイートの総数) が異なるため、信頼性が等しくありません。 この問題は、小さなエリア、つまり観測密度の低いエリアでは悪化します。 したがって、人口値が小さい地域のレートは信頼性が低くなります。
この問題に対処するために、空間適応カーネル スムージング (Tiwari and Rushton 2005) を適用して、近くの観測を考慮してフィーチャの信頼できる密度値を推定できます。
固定距離カーネル平滑化とは異なり、適応カーネル平滑化は、k 最近傍観測 (ツイートやユーザーなど) を使用してレートの分母のしきい値を定義します。k-nearest neighbors を決定するためにユーザー数を使用すると、少数のアクティブ ユーザーがコンテンツの大部分を作成するというユーザー貢献バイアスを取り除くのに役立ちます。 ただし、この研究では、2 つの理由から、ツイート数を使用して k 最近傍を決定します。 第 1 に、位置情報は、ごく少数のユーザーによって生成される可能性がありますが、災害のコンテキストにとって重要です。 第二に、ツイートの大部分は場所タグが付けられているため、ツイートの大部分は正確な座標を共有しています。  

適応カーネル平滑化の定義、式、およびステップを以下に定義します。 ステップ 1 では、エリアが 2.5 km の解像度 (G) のグリッドに分割され、フロリダとハリケーン イルマの近くの影響を受けたエリアがカバーされます。 都市または近隣レベルで同じ大まかな座標を持つ場所タグ付きのツイートがかなりの量あります。 ステップ 2 では、潜在的なバイアスを防ぐために、k 最近傍を決定する前に、正確な座標を共有するツイートを個別のツイート位置に集約します。 したがって、ツイートの総数、ツイートのリスト、およびそれらに割り当てられたトピック確率に関する情報を含む、個別のツイートの場所のリストを取得します。 ツイートの各カテゴリのレートの信頼できる推定値を計算するために、個別のツイートの場所の最小数として k を定義します。 ステップ 3 では、Sort-Tile-Recursive Tree アルゴリズムを使用して、計算効率を向上させるために、各グリッド セルの k 個に最も近い個別のツイート位置のインデックスを計算します。 近傍が定義されたしきい値 k に達すると、ツイートのリスト、Ti、帯域幅 h(Gi,k)、およびステップ 3 で各グリッド セルの個別のツイート位置の重みを決定します。K はカーネル関数です。h は平滑化の帯域幅です。カーネル関数はカーネル内の各観測値の重みを決定し、多くの場合、関数の選択は結果に実質的な影響を与えません。 最も一般的に使用されるカーネル関数は、Uniform、Epanechnikov、Triangular、Gaussian です。 この研究では、ガウス カーネル関数を使用して、各グリッド セルのカーネル内の各ツイートの重みを決定します。 ツイートのリスト、各ツイートの空間重み、およびトピックの確率が与えられると、ステップ 4 で定義された式を使用して、各グリッド セルの各トピックの加重平均確率を計算します。